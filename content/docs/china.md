# AI governance and standardization in China

In 2019, China's New Generation AI Governance Expert Committee published ["Eight principles for AI governance and “responsible AI”](https://perma.cc/V9FL-H6J7).
The motivation behind the proposed principles is the healthy development of a new generation of AI.
If followed, one can ensure that AI is safe/secure, and reliable. 
The eight principles are as follows:

1.	**Harmony and friendliness:** The primary objective of AI should be to enhance the common well-being of humanity. In other words, AI should serve the progress of human civilization while complying with the ethical and moral dimensions, and upholding the societal security and human rights.

2.	**Fairness and justice:** Biasness and discrimination should be avoided in each phase from data gathering to the final product development of AI. Instead, fairness, justice, and equality of opportunity should be promoted. The rights and interests of stakeholders should be protected.

3.	**Inclusivity and sharing:** AI should be for everyone. Coordinated, shared, and inclusive development of AI should be encouraged to secure the adaptability of people from different backgrounds and abilities. Resources should be openly accessible to evade data and platform monopolies.

4.	**Respect privacy:** In the development of AI, personal privacy should be strictly protected. If personal data is used, necessary boundaries and standards should be enforced to protect them. Contributing individuals should have the right to know and decide which data should be used and where they should be used.

5.	**Secure/safe and controllable:** In order to attain trustworthiness, AI systems should emphasize transparency, explainability, reliability, and controllability. The robustness, safety, and security of AI systems must be given special attention, and an external assessment of these components is needed.

6.	**Shared responsibility:** In general, it is the responsibility of AI developers, users, beneficiaries, and all the stakeholders involved to prevent the misuse of AI against laws, regulations, ethics, morals, standards, and norms. When needed, the specific responsibilities of these parties should also be defined.

7.	**Open collaboration:** To promote the healthy development of AI, knowledge and ideas should be shared and exchanged across disciplines, domains, regions, and borders. For collaborations at the international level, consensus on an international AI governance framework, standards, and norms should be initiated.

8.	**Agile governance:** In order to promote the innovative, orderly, and natural development of AI, management mechanisms, governance systems, and recommender practices should be continuously updated. Future risks associated with the advancements in AI should be anticipated and necessary adjustments should be made accordingly.


China has a [multi-layered framework for standardisation of AI](https://cset.georgetown.edu/publication/artificial-intelligence-standardization-white-paper/).

* **Level A - Foundations:**  Foundational standards include the four main categories of terminology, reference architecture, data, and testing and assessment. These standards supports the other parts in the standards system structure. 

* **Level B - Platforms/support:** Supportive technology and product standards provide basic support for artificial intelligence software and hardware platform construction, algorithm model development, and artificial intelligence applications.
Fundamental hardware and software platform standards mainly focus on intelligent chips, system software, development frameworks, etc., to provide infrastructure support for artificial intelligence. 

* **Level C - Key technologies:** Key technology standards a cover topics like natural language processing, human-computer interaction, computer vision, biometric feature recognition, and VR/AR. These standards provide support for practical applications of AI. 

* **Level D - Products and services:** Products/services standards cover 'intelligentized' products and new service models formed in AI technology fields.

* **Level E - Application standard:** These standards focus on specific application areas, e.g. smart homes, smart manufacturing, smart healthcare, etc. 
They focus on needs facing the specific industries, refining other parts of the standards to support the development of various industries. 
 
*  **Level F - Security/ethics:** These standards run through the other parts to establish a compliance system for AI. 
