# Regulation of AI in the United Kingdom

In 2021, the UK Centre for Data Ethics and Innovaion (CDEI)  published a [roadmap](https://www.gov.uk/government/publications/the-roadmap-to-an-effective-ai-assurance-ecosystem), 
which is the first of its kind, setting out the steps required to build a world-leading AI assurance ecosystem in the UK.
Their vision is that the UK will have a thriving and effective AI assurance ecosystem within the next 5 years. 

To provide meaningful and reliable assurance for AI, organisations need to overcome:
* *An information problem:* reliably evaluate evidence to assess whether an AI system is trustworthy.
* *A communication problem:* communicate the evidence at the right level, to inform assurance users’ views on whether to trust an AI system.
Assurance helps to overcome both of these problems.

The UK roadmap describes three roles in relation to AI assurance, i.e., the 1st party role (responsible party), the 2nd party role (assurance user) and the 3rd party role (assurance provider).
The 3rd party conducts assessment, testing and verification of the AI -system for the first party, and provides information about trustworthiness of the AI-system to the 2nd party. This enables the 2nd party to have justified trust in the 1at party. 
In addition, the roadmap describes four sets of key actors in the Ai assurance ecosystem:
* *Simplified AI supply chain:* AI developers, executives deploying AI systems, Frontline users and affected individuals.
* *AI assurance service roviders:* Independent assurance providers and internal assurance teams.
* *Independent research:* Academic researchers and journalists/activists.
* *Supporting structures:* Government, regulators, standards bodies and accreditation/professional bodies.

Based on the main roles of these four important groups of actors in the AI assurance ecosystem, the CDEI have identified six priority areas for developing an effective, mature AI assurance ecosystem:

* *Demand for AI assurance:* The AI supply chain will need to demand, and receive, reliable evidence about the risks of these technologies, so they can make responsible adoption decisions.

* *An AI assurance market:* A competitive, dynamic market of service providers is needed to provide the tools and services to create this reliable evidence in an efficient and effective way.

* *Standards:* Different kinds of standards are needed to build common language and scalable assessment techniques

* *Professionalization:* The governance and incentives for assurance service providers need to be trusted.

* *Regulation:* Beyond auditing and inspecting AI as part of their enforcement activity, regulators will play an important role in supporting the development of the broader AI assurance ecosystem. Regulation can help to enable assurance, by setting assurable requirements that enable organizations to manage their regulatory obligations. Assurance also helps regulators to achieve their objectives by empowering users of AI to achieve compliance and manage risk.

* *Independent research:* In addition to specialized assurance providers, standards, regulatory, industry and professional bodies, other independent actors can offer important services to the assurance ecosystem.
 
